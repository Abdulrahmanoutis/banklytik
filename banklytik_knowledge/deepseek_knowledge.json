{
  "functions": {
    "fix_missing_space_date": {
      "description": "Fix OCR and spacing issues in date strings before parsing.",
      "source": "def fix_missing_space_date(date_str):\n    \"\"\"\n    Fix OCR spacing and colon issues in date strings.\n    Dynamically applies regex rules from both:\n    1. DeepSeek knowledge (JSON)\n    2. Knowledge base (dates_rules.md)\n    Then falls back to internal static patterns.\n    \"\"\"\n    if not isinstance(date_str, str):\n        return date_str\n\n    changed_any = False\n\n    # --- Step 1: Apply DeepSeek patterns (from exported JSON) ---\n    deepseek_rules = get_deepseek_patterns() or []\n    if deepseek_rules:\n        print(f\"\u2705 Loaded DeepSeek rules: {len(deepseek_rules)}\")\n        for rule_text in deepseek_rules:\n            pattern_match = re.search(r\"Regex:\\s*(.+?)\\s+Replace:\", rule_text)\n            replace_match = re.search(r\"Replace:\\s*(.+?)(?:\\s+Notes:|$)\", rule_text)\n            if pattern_match and replace_match:\n                pattern = pattern_match.group(1).strip()\n                replacement = replace_match.group(1).strip()\n                try:\n                    new_str = re.sub(pattern, replacement, date_str)\n                    if new_str != date_str:\n                        print(f\"DEBUG: DeepSeek applied pattern '{pattern}'\")\n                        print(f\"       '{date_str}' -> '{new_str}'\")\n                        date_str = new_str\n                        changed_any = True\n                except re.error as e:\n                    print(f\"\u26a0\ufe0f Regex error in DeepSeek rule '{pattern}': {e}\")\n\n    # --- Step 2: Apply Knowledge Base rules (Markdown) ---\n    kb_rules = get_rules(\"dates\") or []\n    for rule_text in kb_rules:\n        pattern_match = re.search(r\"Regex:\\s*(.+)\", rule_text)\n        replace_match = re.search(r\"Replace:\\s*(.+)\", rule_text)\n        if pattern_match and replace_match:\n            pattern = pattern_match.group(1).strip()\n            replacement = replace_match.group(1).strip()\n            new_str = re.sub(pattern, replacement, date_str)\n            if new_str != date_str:\n                print(f\"DEBUG: KB rule applied: '{pattern}'\")\n                date_str = new_str\n                changed_any = True\n\n    # --- Step 3: Internal legacy fallbacks ---\n    internal_patterns = [\n        (r'(\\d{4}\\s+[A-Za-z]{3,}\\s+)(\\d{2})(\\d{2}:\\d{2}\\s+\\d{2})', r'\\1\\2 \\3'),\n        (r'(\\d{4}\\s+[A-Za-z]{3,}\\s+)(\\d{2})(\\d{2}:\\d{2})', r'\\1\\2 \\3'),\n        (r'(\\d{2})([A-Za-z]{3,})(\\d{4}\\s+\\d{2}:\\d{2})', r'\\1 \\2 \\3'),\n        (r'(\\d{2})(\\d{2}:\\d{2})', r'\\1 \\2'),\n        (r'(\\d{2}:\\d{2}):\\s+(\\d{2})', r'\\1 \\2'),\n    ]\n    for pattern, replacement in internal_patterns:\n        new_str = re.sub(pattern, replacement, date_str)\n        if new_str != date_str:\n            print(f\"DEBUG: Fixed fallback '{pattern}' -> '{new_str}'\")\n            date_str = new_str\n            changed_any = True\n\n    if changed_any:\n        print(f\"DEBUG: Final fixed date string: '{date_str}'\")\n\n    return date_str\n"
    },
    "parse_date_str": {
      "description": "Robust multi-strategy date parser for bank statements.",
      "source": "def parse_date_str(date_str):\n    \"\"\"Robust multi-strategy date parser with enhanced Kuda/Access format support.\"\"\"\n    import re\n    import pandas as pd\n    from datetime import datetime\n    import dateparser\n\n    if pd.isna(date_str):\n        return None\n\n    s = str(date_str).strip()\n    if s.lower() in [\"\", \"nan\", \"none\", \"null\", \"0.0\"]:\n        return None\n\n    # Normalize spaces and separators\n    s = re.sub(r\"(\\d{1,2})([A-Za-z]{3,})(\\d{4})\", r\"\\1 \\2 \\3\", s)\n    s = re.sub(r\"(\\d{4})([A-Za-z]{3,})(\\d{1,2})\", r\"\\1 \\2 \\3\", s)\n    s = re.sub(r\"(\\d{2})([A-Za-z]{3,})(\\d{2})\", r\"\\1 \\2 \\3\", s)\n    s = re.sub(r\"[\\t\\r\\n]+\", \" \", s)\n    s = re.sub(r\"\\s{2,}\", \" \", s).strip()\n    s = s.replace(\"  \", \" \")\n\n    # --- 1. Try dateparser first ---\n    try:\n        parsed = dateparser.parse(\n            s,\n            settings={\n                \"DATE_ORDER\": \"DMY\",\n                \"PREFER_DAY_OF_MONTH\": \"first\",\n                \"PREFER_DATES_FROM\": \"current_period\",\n                \"RETURN_AS_TIMEZONE_AWARE\": False,\n            },\n        )\n        if parsed:\n            return parsed\n    except Exception:\n        pass\n\n    # --- 2. Manual known formats ---\n    common_formats = [\n        \"%d %b %Y %I:%M %p\",  # 15 Oct 2025 07:32 PM\n        \"%b %d, %Y %H:%M:%S\",\n        \"%b %d, %Y %I:%M %p\",\n        \"%d %b, %Y %H:%M\",\n        \"%Y-%m-%d %H:%M:%S\",\n        \"%Y-%m-%dT%H:%M:%S\",\n        \"%d/%m/%Y %H:%M\",\n        \"%d-%m-%Y %H:%M\",\n        \"%d %b %Y\",\n        \"%b %d %Y\",\n    ]\n    for fmt in common_formats:\n        try:\n            parsed = datetime.strptime(s, fmt)\n            return parsed\n        except Exception:\n            continue\n\n    # --- 3. Fallback using pandas ---\n    try:\n        parsed = pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n        if not pd.isna(parsed):\n            return parsed.to_pydatetime()\n    except Exception:\n        pass\n\n    # --- 4. Log unparsed date for DeepSeek learning ---\n    try:\n        from banklytik_core.deepseek_rule_generator import log_failed_date\n        log_failed_date(s, \"unparsed_kuda_like_date\")\n    except Exception:\n        pass\n\n    return None\n"
    },
    "robust_clean_dataframe": {
      "description": "Top-level cleaning pipeline for statement DataFrames.",
      "source": "def robust_clean_dataframe(df_raw):\n    \"\"\"Clean extracted statement tables safely and robustly.\"\"\"\n    print(\"DEBUG: robust_clean_dataframe input shape:\", df_raw.shape)\n\n    df = df_raw.copy()\n    df = df.applymap(lambda v: normalize_text(v) if pd.notna(v) else \"\")\n\n    headers = [\n        \"Trans. Time\", \"Value Date\", \"Description\",\n        \"Debit/Credit(W)\", \"Balance(N)\", \"Channel\", \"Transaction Reference\"\n    ]\n    df.columns = headers[:len(df.columns)]\n\n    print(\"DEBUG: First 5 date strings in 'Trans. Time':\")\n    for i, date_str in enumerate(df[\"Trans. Time\"].head(5)):\n        print(f\"  {i}: '{date_str}'\")\n\n    df[\"raw_date\"] = df[\"Trans. Time\"]\n    df[\"date\"] = df[\"Trans. Time\"].apply(parse_date_str)\n    df[\"value_date\"] = df[\"Value Date\"].apply(parse_date_str)\n    df[\"description\"] = df[\"Description\"]\n    df[\"balance\"] = df[\"Balance(N)\"].apply(clean_amount)\n\n    dc = df[\"Debit/Credit(W)\"].astype(str)\n    df[\"debit\"] = dc.apply(lambda x: clean_amount(x) if \"-\" in x else 0.0)\n    df[\"credit\"] = dc.apply(lambda x: clean_amount(x) if \"+\" in x else 0.0)\n\n    df[\"channel\"] = df[\"Channel\"].apply(extract_channel)\n    df[\"transaction_reference\"] = df[\"Transaction Reference\"]\n\n    def detect_issues(row):\n        issues = []\n        if row[\"date\"] is None:\n            issues.append(\"invalid_date\")\n        if row[\"value_date\"] is None:\n            issues.append(\"invalid_value_date\")\n        if isinstance(row[\"balance\"], str) and \"INVALID_AMOUNT\" in row[\"balance\"]:\n            issues.append(\"invalid_balance\")\n        if row[\"channel\"] == \"EMPTY\":\n            issues.append(\"missing_channel\")\n        return \", \".join(issues) if issues else \"\"\n\n    df[\"row_issue\"] = df.apply(detect_issues, axis=1)\n\n    print(\"DEBUG: Cleaned shape:\", df.shape)\n    print(\"DEBUG: Date parsing summary:\")\n    print(f\"  - Valid dates: {df['date'].notna().sum()}\")\n    print(f\"  - Invalid dates: {df['date'].isna().sum()}\")\n\n    return df[\n        [\"date\", \"raw_date\", \"value_date\", \"description\", \"debit\", \"credit\",\n         \"balance\", \"channel\", \"transaction_reference\", \"row_issue\"]\n    ]\n"
    }
  },
  "rules": {
    "dates": [],
    "amounts": [],
    "text_normalization": []
  },
  "examples": {
    "dates": [],
    "amounts": [],
    "text_normalization": []
  }
}